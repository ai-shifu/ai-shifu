{
  "__namespace__": "server.llm",
  "__flat__": {
    "modelNotSupported": "Model {model} is not supported",
    "requestFailed": "Model {model} invocation failed: {message}",
    "specifiedLlmNotConfigured": "Model {model} is not configured. Check .env file variable: {config_var}"
  }
}
